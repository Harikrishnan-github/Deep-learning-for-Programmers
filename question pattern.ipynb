{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each questions carries 0.1 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[True or False] Android Malware detection using Deep Learning is a many-to one prediction task\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "Solution: A\n",
    "\n",
    "Option A is correct. This is because from a sequence of features, you have to predict whether the EXE file is benign or malware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What steps can we take to prevent overfitting in a Neural Network?\n",
    "\n",
    "A) Data Augmentation\n",
    "B) Weight Sharing\n",
    "C) Early Stopping\n",
    "D) Dropout\n",
    "E) All of the above\n",
    "\n",
    "Solution: E\n",
    "\n",
    "All of the above mentioned methods can help in preventing overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM can help prevent vanishing gradient problem in RNN.\n",
    "\n",
    "A) True\n",
    "B) False\n",
    "\n",
    "Solution: A\n",
    "\n",
    "Option A is correct. This is because it has implicit memory to remember past behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which of the following statement is true regrading dropout?\n",
    "\n",
    "1: Dropout gives a way to approximate by combining many different architectures\n",
    "2: Dropout demands high learning rates\n",
    "3: Dropout can help preventing overfitting\n",
    "\n",
    "A) Both 1 and 2\n",
    "B) Both 1 and 3\n",
    "C) Both 2 and 3\n",
    "D) All 1, 2 and 3\n",
    "\n",
    "Solution: B\n",
    "\n",
    "Statements 1 and 3 are correct, statement 2 is not always true. Even after applying dropout and with low learning rate, a neural network can learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In CNN, having max pooling always decrease the parameters?\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "Solution: B\n",
    "\n",
    "This is not always true. If we have a max pooling layer of pooling size as 1, the parameters would remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True/False: Changing Sigmoid activation to ReLu will help to get over the vanishing gradient issue?\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "Solution: A\n",
    "\n",
    "ReLU can help in solving vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which of following activation function can’t be used at output layer to classify an image ?\n",
    "\n",
    "A) sigmoid\n",
    "B) Tanh\n",
    "C) ReLU\n",
    "D) If(x>5,1,0)\n",
    "E) None of the above\n",
    "\n",
    "Solution: C\n",
    "\n",
    "ReLU gives continuous output in range 0 to infinity. But in output layer, we want a finite range of values. So option C is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assume a simple MLP model with 3 neurons and inputs= 1,2,3. The weights to the input neurons are 4,5 and 6 respectively. Assume the activation function is a linear constant value of 3. What will be the output ?\n",
    "\n",
    "A) 32\n",
    "B) 643\n",
    "C) 96\n",
    "D) 48\n",
    "\n",
    "Solution: C\n",
    "\n",
    "The output will be calculated as 3(1*4+2*5+6*3) = 96\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which of the following functions can be used as an activation function in the output layer if we wish to predict the probabilities of n classes (p1, p2..pk) such that sum of p over all n equals to 1?\n",
    "\n",
    "A) Softmax\n",
    "B) ReLu\n",
    "C) Sigmoid\n",
    "D) Tanh\n",
    "\n",
    "Solution: A\n",
    "\n",
    "Softmax function is of the form  in which the sum of probabilities over all k sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In a simple MLP model with 8 neurons in the input layer, 5 neurons in the hidden layer and 1 neuron in the output layer. What is the size of the weight matrices between hidden output layer and input hidden layer?\n",
    "\n",
    "A) [1 X 5] , [5 X 8]\n",
    "\n",
    "B) [8 X 5] , [ 1 X 5]\n",
    "\n",
    "C) [8 X 5] , [5 X 1]\n",
    "\n",
    "D) [5 x 1] , [8 X 5]\n",
    "\n",
    "Solution: D\n",
    "\n",
    "The size of weights between any layer 1 and layer 2 Is given by [nodes in layer 1 X nodes in layer 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The input image has been converted into a matrix of size 28 X 28 and a kernel/filter of size 7 X 7 with a stride of 1. What will be the size of the convoluted matrix?\n",
    "\n",
    "A) 22 X 22\n",
    "B) 21 X 21\n",
    "C) 28 X 28\n",
    "D) 7 X 7\n",
    "\n",
    "Solution: A\n",
    "\n",
    "The size of the convoluted matrix is given by C=((I-F+2P)/S)+1, where C is the size of the Convoluted matrix, I is the size of the input matrix, F the size of the filter matrix and P the padding applied to the input matrix. Here P=0, I=28, F=7 and S=1.  There the answer is 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a11846e5a8f1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a11846e5a8f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Linear algebra operations\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Linear algebra operations\n",
    "Implement a function l2norm that takes a vector as its argument and returns its l2norm norm.\n",
    "Implement a function euclid_dist that takes two vectors as its arguments and returns the euclidean distance between the vectors.\n",
    "Implement a function cosine_sim that takes two vectors as its arguments and returns the cosine similarity between the vectors (cos Θ).\n",
    "\n",
    "Note: you can use the math.sqrt or np.sqrt function for computing the square root. You can use the regular - operator for elementwise subtraction of vector components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b7a26a4da18e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b7a26a4da18e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return np.sqrt(v @ v)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def l2norm(v):\n",
    "    return np.sqrt(v @ v)\n",
    "\n",
    "l2norm(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dist(u, v):\n",
    "    return l2norm(u - v)\n",
    "euclid_dist(np.array([2, 0]), np.array([0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(u, v):\n",
    "    return (u @ v) / (l2norm(u) * l2norm(v))\n",
    "cosine_sim(np.array([2,1]), np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Broadcasting\n",
    "Try to sum a tensor of shape (2, 1, 3) and a tensor of shape (2, 3, 1) elementwise. Explain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 6).reshape((2, 1, 3))\n",
    "b = np.arange(0, 6).reshape((2, 3, 1))\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions based on the numpy, scipy, pandas and matplotlib functions: 0.25 marks\n",
    "    \n",
    "np.array()\n",
    "ndarray.shape, .size, .ndim, .dtype, .T \n",
    "np.zeros(), np.ones(), np.arange(). np.eye()\n",
    "np.reshape(), np.ravel() \n",
    "np.amax(), np.maximum(), np.sum(), np.mean,() np.std() \n",
    "np.stack(), np.[hv]stack(), np.column_stack(), np.split() \n",
    "np.exp(), np.log(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consider the following table that describes a relationship between two input variables (x1,x2) and an output variable (y).\n",
    "(Table will be given)\n",
    "Using your favorite language, find the least squares solution to y = w1 * x1 + w2 * x2 + b.\n",
    "\n",
    "(1a) Report the values of w1, w2, and b.\n",
    "(1b) What function or method did you use to find the least-squares solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quesions based on CNN, CNN-RNN, CNN,LSTM, CNN-GRU, Bidirectional algorithms (Sample data will be given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep learning has shown great performance in computer vision, speech recognition, and\n",
    "natural language processing. It has also shown its potential in planning and playing games.\n",
    "What will be another application that you think current deep learning techniques fit and\n",
    "why? What will be an application that you think current deep learning techniques do NOT\n",
    "fit and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "securetensor",
   "language": "python",
   "name": "securetensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
